{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOG6cKGcvQjiMw7hTk0m4K9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MominaGull/ML-Practice-Projects/blob/main/Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYhiF34urFk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d2f3c2cc-d131-4c46-f8b3-74c52415a5ee"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTEXHYurU81"
      },
      "source": [
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "    for sentence in article:\n",
        "     print(sentence)\n",
        "     sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "     sentences.pop() \n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQfNNeHesDvx"
      },
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbnvy3BCrXzZ"
      },
      "source": [
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "    return similarity_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWEtHA5rhwK"
      },
      "source": [
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "    # Step 1 - Read text and tokenize\n",
        "    sentences =  read_article(file_name)\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "    # Step 5 - Offcourse, output the summarize texr\n",
        "      print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLB2mQwVtZtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cf541fe-535f-4a36-9987-2d1e3cd1924e"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        " \n",
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        " \n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5\n",
        "    x = \"Summarize Text: \\n\", \". \".join(summarize_text)\n",
        "    with open('/content/new.txt', 'w') as f:\n",
        "      for item in x:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "# let's begin\n",
        "generate_summary( \"/content/summary.txt\", 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction\n",
            "These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics\n",
            "Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer\n",
            "Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.Machine-learning technology powers many aspects of modern society from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones\n",
            "Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search\n",
            "Increasingly, these applications make use of a class of techniques called deep learning\n",
            "Conventional machine-learning techniques were limited in their ability to process natural data in their raw form\n",
            "For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input\n",
            "Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification\n",
            "Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level\n",
            "With the composition of enough such transformations, very complex functions can be learned\n",
            "For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations\n",
            "An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image\n",
            "The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions\n",
            "The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts\n",
            "The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure\n",
            "Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years\n",
            "It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government\n",
            "In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data,reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease\n",
            "Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation\n",
            "We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data\n",
            "New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.The most common form of machine learning, deep or not, is supervised learning\n",
            "Imagine that we want to build a system that can classify images as containing, say, a house, a car, a person or a pet\n",
            "We first collect a large data set of images of houses, cars, people and pets, each labelled with its category\n",
            "During training, the machine is shown an image and produces an output in the form of a vector of scores, one for each category\n",
            "We want the desired category to have the highest score of all categories, but this is unlikely to happen before training.We compute an objective function that measures the error (or distance) between the output scores and the desired pattern of scores\n",
            "The machine then modifies its internal adjustable parameters to reduce this error\n",
            "These adjustable parameters, often called weights, are real numbers that can be seen as ‘knobs’ that define the input–output function of the machine\n",
            "In a typical deep-learning system, there may be hundreds of millions of these adjustable weights, and hundreds of millions of labelled examples with which to train the machine.To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount\n",
            "The weight vector is then adjusted in the opposite direction to the gradient vector\n",
            "The objective function, averaged over all the training examples, can be seen as a kind of hilly landscape in the high-dimensional space of weight values\n",
            "The negative gradient vector indicates the direction of steepest descent in this landscape, taking it closer to a minimum, where the output error is low on average.In practice, most practitioners use a procedure called stochastic gradient descent (SGD)\n",
            "This consists of showing the input vector for a few examples, computing the outputs and the errors, computing the average gradient for those examples, and adjusting the weights accordingly\n",
            "The process is repeated for many small sets of examples from the training set until the average of the objective function stops decreasing\n",
            "It is called stochastic because each small set of examples gives a noisy estimate of the average gradient over all examples\n",
            "This simple procedure usually finds a good set of weights surprisingly quickly when compared with far more elaborate optimization techniques\n",
            "After training, the performance of the system is measured on a different set of examples called a test set\n",
            "This serves to test the generalization ability of the machine — its ability to produce sensible answers on new inputs that it has never seen during training\n",
            "Many of the current practical applications of machine learning use linear classifiers on top of hand-engineered features\n",
            "A two-class linear classifier computes a weighted sum of the feature vector components.If the weighted sum is above a threshold, the input is classified as belonging to a particular category\n",
            "Since the 1960s we have known that linear classifiers can only carve their input space into very simple regions, namely half-spaces separated by a hyperplane\n",
            "But problems such as image and speech recognition require the input–output function to be insensitive to irrelevant variations of the input, such as variations in position, orientation or illumination of an object, or variations in the pitch or accent of speech, while being very sensitive to particular minute variations (for example,the difference between a white wolf and a breed of wolf-like white dog called a Samoyed)\n",
            "At the pixel level, images of two Samoyeds in different poses and in different environments may be very different from each other, whereas two images of a Samoyed and a wolf in the same position and on similar backgrounds may be very similar to eachother\n",
            "A linear classifier, or any other ‘shallow’ classifier operating on  A multi layer neural network can distort the input space to make the classes of data linearly separable\n",
            "Note how a regular grid in input space is also transformed by hidden units\n",
            "This is an illustrative example with only two input units, two hidden units and one output unit, but the networks used for object recognition or natural language processing contain tens or hundreds of thousands of units\n",
            "The chain rule of derivatives tells us how two small effects (that of a small change of x on y, and that of y on z) are composed\n",
            "A small change Δx in x gets transformed first into a small change Δy in y by getting multiplied by ∂y/∂x (that is, the definition of partial derivative)\n",
            "Similarly, the changeΔy creates a change Δz in z\n",
            "Substituting one equation into the other gives the chain rule of derivatives — how Δx gets turned into Δz through multiplication by the product of ∂y/∂x and ∂z/∂x\n",
            "It also works when x, y and z are vectors (and the derivatives are Jacobian matrices)\n",
            "c, The equations used for computing the forward pass in a neural net with two hidden layers and one output layer, each constituting a module through which one can backpropagate gradients\n",
            "At each layer, we first compute the total input z to each unit, which is a weighted sum of the outputs of the units in the layer below\n",
            "Then a non-linear function f(.) is applied to z to get the output of the unit\n",
            "For simplicity, we have omitted bias terms.The non-linear functions used in neural networks include the rectified linear unit (ReLU) f(z) = max(0,z), commonly used in recent years, aswell as the more conventional sigmoids, such as the hyberbolic tangent,f(z) =(exp(z)− exp(−z))/(exp(z)+exp(−z)) and logistic function logistic,f(z) =1/(1 + exp(−z))\n",
            "d, The equations used for computing the backward pass\n",
            "At each hidden layer we compute the error derivative with respect to the output of each unit, which is a weighted sum of the error derivatives with respect to the total inputs to the units in the layer above\n",
            "We then convert the error derivative with respect to the output into the error derivative with respect to the input by multiplying it by the gradient of f(z).At the output layer, the error derivative with respect to the output of a unit is computed by differentiating the cost function\n",
            "This gives yl−tl if the cost function for unit l is 0.5(yl−tl), where tl is the target value\n",
            "Once the ∂E/∂z k is known, the error-derivative for the weight wjk on the connection from unit j in the layer below is just yj ∂E/∂zk\n",
            "raw pixels could not possibly distinguish the latter two, while putting the former two in the same category\n",
            "This is why shallow classifiers require a good feature extractor that solves the selectivity–invariance dilemma — one that produces representations that are selective to the aspects of the image that are important for discrimination, but that are invariant to irrelevant aspects such as the pose of the animal.To make classifiers more powerful, one can use generic non-linear features, as with kernel methods, but generic features such as those arising with the Gaussian kernel do not allow the learner to generalize well far from the training examples\n",
            "The conventional option is to hand design good feature extractors, which requires a considerable amount of engineering skill and domain expertise\n",
            "But this can all be avoided if good features can be learned automatically using a general-purpose learning procedure\n",
            "This is the key advantage of deep learning.A deep-learning architecture is a multi layer stack of simple modules, all (or most) of which are subject to learning, and many of which compute non-linear input–output mappings\n",
            "Each module in the stack transforms its input to increase both the selectivity and the invariance of the representation\n",
            "With multiple non-linear layers, say a depth of 5 to 20, a system can implement extremely intricate functions of its inputs that are simultaneously sensitive to minute details— distinguishing Samoyeds from white wolves — and insensitive to large irrelevant variations such as the background, pose, lighting and surrounding objects\n",
            "Backpropagation to train multi layer architectures\n",
            "From the earliest days of pattern recognition, the aim of researchers has been to replace hand-engineered features with trainable multi layer networks, but despite its simplicity, the solution was not widely understood until the mid 1980s\n",
            "As it turns out, multi layer architectures can be trained by simple stochastic gradient descent.As long as the modules are relatively smooth functions of their inputs and of their internal weights, one can compute gradients using the backpropagation procedure\n",
            "The idea that this could be done, and that it worked, was discovered independently by several different groups during the 1970s and 1980s.The backpropagation procedure to compute the gradient of an objective function with respect to the weights of a multi layer stack of modules is nothing more than a practical application of the chain rule for derivatives\n",
            "The key insight is that the derivative (or gradient) of the objective with respect to the input of a module can be computed by working backwards from the gradient with respect to the output of that module (or the input of the subsequent module)\n",
            "The backpropagation equation can be applied repeatedly to propagate gradients through all modules, starting from the output at the top (where the network produces its prediction) all the way to the bottom (where the external input is fed)\n",
            "Once these gradients have been computed, it is straightforward to compute the gradients with respect to the weights of each module.Many applications of deep learning use feedforward neural network architectures, which learn to map a fixed-size input(for example, an image) to a fixed-size output (for example, a probability for each of several categories)\n",
            "To go from one layer to the next, a set of units compute a weighted sum of their inputs from the previous layer and pass the result through a non-linear function\n",
            "At present, the most popular non-linear function is the rectified linear unit (ReLU), which is simply the half-wave rectifier f(z)= max(z, 0).In past decades, neural nets used smoother non-linearities, such as tanh(z) or 1/(1+exp(−z)), but the ReLU typically learns much faster in networks with many layers, allowing training of a deep supervised network without unsupervised pre-training\n",
            "Units that are not in the input or output layer are conventionally called hidden units\n",
            "The hidden layers can be seen as distorting the input in a non-linear way so that categories become linearly separable by the last layer.In the late 1990s, neural nets and backpropagation were largely forsaken by the machine-learning community and ignored by the computer-vision and speech-recognition communities\n",
            "It was widely thought that learning useful, multistage, feature extractors with little prior knowledge was infeasible\n",
            "In particular, it was commonly thought that simple gradient descent would get trapped in poor local minima — weight configurations for which no small change would reduce the average error.In practice, poor local minima are rarely a problem with large networks\n",
            "Regardless of the initial conditions, the system nearly always reaches solutions of very similar quality\n",
            "Recent theoretical and empirical results strongly suggest that local minima are not a serious issue in general\n",
            "Instead, the landscape is packed with a combinatorially large number of saddle points where the gradient is zero, and the surface curves up in most dimensions and curves down in the remainder\n",
            "The analysis seems to show that saddle points with only a few downward curving directions are present in very large numbers, but almost all of them have very similar values of the objective function\n",
            "Hence, it does not much matter which of these saddle points the algorithm gets stuck at.Interest in deep feedforward networks was revived around 2006 by a group of researchers brought together by the Canadian Institute for Advanced Research (CIFAR)\n",
            "The researchers introduced unsupervised learning procedures that could create layers of feature detectors without requiring labelled data\n",
            "The objective in learning each layer of feature detectors was to be able to reconstructor model the activities of feature detectors (or raw inputs) in the layer below\n",
            "By ‘pre-training’ several layers of progressively more complex feature detectors using this reconstruction objective, the weights of a deep network could be initialized to sensible values\n",
            "A final layer of output units could then be added to the top of the network and the whole deep system could be fine-tuned using standard backpropagation\n",
            "This worked remarkably well for recognizing handwritten digits or for detecting pedestrians, especially when the amount of labelled data was very limited.The first major application of this pre-training approach was inspeech recognition, and it was made possible by the advent of fast graphics processing units (GPUs) that were convenient to program and allowed researchers to train networks 10 or 20 times faster\n",
            "In2009, the approach was used to map short temporal windows of coefficients extracted from a sound wave to a set of probabilities for thevarious fragments of speech that might be represented by the framein the centre of the window\n",
            "It achieved record-breaking results on a standard speech recognition benchmark that used a small vocabulary and was quickly developed to give record-breaking results on a large vocabulary task\n",
            "By 2012, versions of the deep net from 200 were being developed by many of the major speech groups and were already being deployed in Android phones\n",
            "For smaller data sets,unsupervised pre-training helps to prevent overfitting, leading to significantly better generalization when the number of labelled examples is small, or in a transfer setting where we have lots of examples for some ‘source’ tasks but very few for some ‘target’ tasks\n",
            "Once deeplearning had been rehabilitated, it turned out that the pre-training stage was only needed for small data sets.There was, however, one particular type of deep, feedforward network that was much easier to train and generalized much better than networks with full connectivity between adjacent layers\n",
            "This was the convolutional neural network (ConvNet)\n",
            "It achieved many practical successes during the period when neural networks were out of favour and it has recently been widely adopted by the computer vision community.Convolutional neural networks ConvNets are designed to process data that come in the form of multiple arrays, for example a colour image composed of three 2Darrays containing pixel intensities in the three colour channels\n",
            "Many data modalities are in the form of multiple arrays: 1D for signals and sequences, including language; 2D for images or audio spectrograms;and 3D for video or volumetric images\n",
            "There are four key ideas behind ConvNets that take advantage of the properties of natural signals: local connections, shared weights, pooling and the use of many layers.The architecture of a typical ConvNet is structured as a series of stages\n",
            "The first few stages are composed of two types of layers: convolutional layers and pooling layers\n",
            "Units in a convolutional layer are organized in feature maps, within which each unit is connected to local patches in the feature maps of the previous layer through a set of weights called a filter bank\n",
            "The result of this local weighted sum is then passed through a non-linearity such as a ReLU\n",
            "All units in a feature map share the same filter bank\n",
            "Different feature maps in a layer use different filter banks\n",
            "The reason for this architecture is twofold\n",
            "First, in array data such as images, local groups of values are often highly correlated, forming distinctive local motifs that are easily detected\n",
            "Second, the local statistics of images and other signals are invariant to location\n",
            "In other words, if a motifcan appear in one part of the image, it could appear anywhere, hence the idea of units at different locations sharing the same weights and detecting the same pattern in different parts of the array\n",
            "Mathematically, the filtering operation performed by a feature map is a discrete convolution, hence the name.Although the role of the convolutional layer is to detect local conjunctions of features from the previous layer, the role of the pooling layer is to merge semantically similar features into one\n",
            "Because the relative positions of the features forming a motif can vary somewhat,reliably detecting the motif can be done by coarse-graining the position of each feature\n",
            "A typical pooling unit computes the maximum of a local patch of units in one feature map (or in a few feature maps).Neighbouring pooling units take input from patches that are shifted by more than one row or column, thereby reducing the dimension of the representation and creating an invariance to small shifts and distortions\n",
            "Two or three stages of convolution, non-linearity and pooling are stacked, followed by more convolutional and fully-connected layers\n",
            "Backpropagating gradients through a ConvNet is as simple as through a regular deep network, allowing all the weights in all the filter banks to be trained.Deep neural networks exploit the property that many natural signals are compositional hierarchies, in which higher-level features are obtained by composing lower-level ones\n",
            "In images, local combinations of edges form motifs, motifs assemble into parts, and parts form objects\n",
            "Similar hierarchies exist in speech and text from sounds to phones, phonemes, syllables, words and sentences\n",
            "The pooling allows representations to vary very little when elements in the previous layer vary in position and appearance.The convolutional and pooling layers in ConvNets are directly inspired by the classic notions of simple cells and complex cells in visual neuroscience, and the overall architecture is reminiscent of the LGN–V1–V2–V4–IT hierarchy in the visual cortex ventral pathway\n",
            "When ConvNet models and monkeys are shown the same picture, the activations of high-level units in the ConvNet explains half of the variance of random sets of 160 neurons in the monkey’s infero temporal cortex\n",
            "ConvNets have their roots in the neocognitron,the architecture of which was somewhat similar, but did not have an end-to-end supervised-learning algorithm such as backpropagation.A primitive 1D ConvNet called a time-delay neural net was used for the recognition of phonemes and simple words.There have been numerous applications of convolutional networks going back to the early 1990s, starting with time-delay neural networks for speech recognition and document reading\n",
            "The document reading system used a ConvNet trained jointly with a probabilistic model that implemented language constraints\n",
            "By the late 1990s this system was reading over 10% of all the cheques in the United States\n",
            "A number of ConvNet-based optical character recognition and handwriting recognition systems were later deployed by Microsoft\n",
            "ConvNets were also experimented with in the early 1990s for object detection in natural images, including faces and hands,and for face recognition.Image understanding with deep convolutional networks Since the early 2000s, ConvNets have been applied with great success to the detection, segmentation and recognition of objects and regions in images\n",
            "These were all tasks in which labelled data was relatively abundant, such as traffic sign recognition, the segmentation of biological images particularly for connectomics, and the detection of faces,text, pedestrians and human bodies in natural images\n",
            "A major recent practical success of ConvNets is face recognition.Importantly, images can be labelled at the pixel level, which will have applications in technology, including autonomous mobile robots and self-driving cars\n",
            "Companies such as Mobileye and NVIDIA are using such ConvNet-based methods in their upcoming vision systems for cars\n",
            "Other applications gaining importance involve natural language understanding and speech recognition.Despite these successes, ConvNets were largely forsaken by the mainstream computer-vision and machine-learning communities until the ImageNet competition in 2012\n",
            "When deep convolutional networks were applied to a data set of about a million images from the web that contained 1,000 different classes, they achieved spectacular results, almost halving the error rates of the best competing approaches\n",
            "This success came from the efficient use of GPUs,ReLUs, a new regularization technique called dropout, and techniques to generate more training examples by deforming the existing ones\n",
            "This success has brought about a revolution in computer vision;ConvNets are now the dominant approach for almost all recognition and detection tasks and approach human performance on some tasks\n",
            "A recent stunning demonstration combines ConvNets and recurrent net modules for the generation of image captions.Recent ConvNet architectures have 10 to 20 layers of ReLUs, hundreds of millions of weights, and billions of connections between units\n",
            "Whereas training such large networks could have taken weeks only two years ago, progress in hardware, software and algorithm parallelization have reduced training times to a few hours.The performance of ConvNet-based vision systems has caused most major technology companies, including Google, Facebook, Microsoft, IBM, Yahoo!, Twitter and Adobe, as well as a quickly growing number of start-ups to initiate research and development projects and to deploy ConvNet-based image understanding products and services\n",
            "ConvNets are easily amenable to efficient hardware implementations in chips or field-programmable gate arrays\n",
            "A number of companies such as NVIDIA, Mobileye, Intel, Qualcomm and Samsung are developing ConvNet chips to enable real-time vision applications in smartphones, cameras, robots and self-driving cars.Distributed representations and language processing Deep-learning theory shows that deep nets have two different exponential advantages over classic learning algorithms that do not use distributed representations\n",
            "Both of these advantages arise from the power of composition and depend on the underlying data-generating distribution having an appropriate componential structure\n",
            "First,learning distributed representations enable generalization to new combinations of the values of learned features beyond those seen during training (for example, 2n combinations are possible with n binary features)\n",
            "Second, composing layers of representation in a deep net brings the potential for another exponential advantage(exponential in the depth).The hidden layers of a multi layer neural network learn to represent the network’s inputs in a way that makes it easy to predict the target outputs\n",
            "This is nicely demonstrated by training a multi layer neural network to predict the next word in a sequence from a local context of earlier words\n",
            "Each word in the context is presented to the network as a one-of-N vector, that is, one component has a value of 1 and the rest are 0\n",
            "In the first layer, each word creates a different pattern of activations, or word vectors\n",
            "In a language model,the other layers of the network learn to convert the input word vectors into an output word vector for the predicted next word, which can be used to predict the probability for any word in the vocabulary to appear as the next word\n",
            "The network learns word vectors that contain many active components each of which can be interpreted as a separate feature of the word, as was first demonstrated in the context of learning distributed representations for symbols\n",
            "These semantic features were not explicitly present in the input\n",
            "They were discovered by the learning procedure as a good way of factorizing the structured relationships between the input and output symbols into multiple ‘micro-rules’\n",
            "Learning word vectors turned out to also work very well when the word sequences come from a large corpus of real text and the individual micro-rules are unreliable\n",
            "When trained to predict the next word in a news story, for example, the learned word vectors for Tuesday and Wednesday are very similar, as are the word vectors for Sweden and Norway\n",
            "Such representations are called distributed representations because their elements (the features) are not mutually exclusive and their many configurations correspond to the variations seen in the observed data\n",
            "These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network\n",
            "Vector representations of words learned from text are now very widely used in natural language applications.The issue of representation lies at the heart of the debate between the logic-inspired and the neural-network-inspired paradigms for cognition\n",
            "In the logic-inspired paradigm, an instance of a symbol is something for which the only property is that it is either identical or non-identical to other symbol instances\n",
            "It has no internal structure that is relevant to its use; and to reason with symbols, they must be bound to the variables in judiciously chosen rules of inference\n",
            "By contrast, neural networks just use big activity vectors, big weight matrices and scalar non-linearities to perform the type of fast ‘intuitive’ inference that underpins effortless commonsense reasoning.Before the introduction of neural language models, the standard approach to statistical modelling of language did not exploit distributed representations: it was based on counting frequencies of occurrences of short symbol sequences of length up to N (called N-grams).The number of possible N-grams is on the order of VN, where V is the vocabulary size, so taking into account a context of more than a handful of words would require very large training corpora\n",
            "N-grams treat each word as an atomic unit, so they cannot generalize across semantically related sequences of words, whereas neural language models can because they associate each word with a vector of real valued features, and semantically related words end up close to each other in that vector space.Recurrent neural networks When backpropagation was first introduced, its most exciting use was for training recurrent neural networks (RNNs)\n",
            "For tasks that involve sequential inputs, such as speech and language, it is often better to use RNNs\n",
            "RNNs process an input sequence one element at a time, maintaining in their hidden units a ‘state vector’ that implicitly contains information about the history of all the past elements of the sequence\n",
            "When we consider the outputs of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multi layer network, it becomes clear how we can apply backpropagation to train RNNs\n",
            "RNNs are very powerful dynamic systems, but training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish.Thanks to advances in their architecture and ways of training them, RNNs have been found to be very good at predicting the next character in the text or the next word in a sequence, but they can also be used for more complex tasks\n",
            "For example, after reading an English sentence one word at a time, an English ‘encoder’ network can be trained so that the final state vector of its hidden units is a good representation of the thought expressed by the sentence\n",
            "This thought vector can then be used as the initial hidden state of (or as extra input to) a jointly trained French ‘decoder’ network, which outputs a probability distribution for the first word of the French translation\n",
            "If a particular first word is chosen from this distribution and provided as input to the decoder network it will then output a probability distribution for the second word of the translation and so on until a full stop is chosen\n",
            "Overall, this process generates sequences of French words according to a probability distribution that depends on the English sentence\n",
            "This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art,and this raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules\n",
            "It is more compatible with the view that everyday reasoning involves many simultaneous analogies that each contribute plausibility to a conclusion.Instead of translating the meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image into an English sentence\n",
            "The encoder here is a deep ConvNet that converts the pixels into an activity vector in its last hidden layer\n",
            "The decoder is an RNN similar to the ones used for machine translation and neural language modelling\n",
            "There has been a surge of interest in such systems recently.RNNs, once unfolded in time, can be seen as very deep feedforward networks in which all the layers share the same weights.Although their main purpose is to learn long-term dependencies,theoretical and empirical evidence shows that it is difficult to learn to store information for very long.To correct for that, one idea is to augment the network with an explicit memory\n",
            "The first proposal of this kind is the long short-term memory (LSTM) networks that use special hidden units, the natural behaviour of which is to remember inputs for a long time\n",
            "A special unit called the memory cell acts like an accumulator or a gated leaky neuron: it has a connection to itself at the next time step that has a weight of one, so it copies its own real-valued state and accumulates the external signal, but this self-connection is multiplicatively gated by another unit that learns to decide when to clear the content of the memory\n",
            "LSTM networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription\n",
            "LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation.Over the past year, several authors have made different proposals to augment RNNs with a memory module\n",
            "Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’memory that the RNN can choose to read from or write to, and memory networks, in which a regular network is augmented by a kind of associative memory\n",
            "Memory networks have yielded excellent performance on standard question-answering benchmarks\n",
            "The memory is used to remember the story about which the network is later asked to answer questions\n",
            "Beyond simple memorization, neural Turing machines and memory networks are being used for tasks that would normally require reasoning and symbol manipulation\n",
            "Neural Turing machines can be taught ‘algorithms’\n",
            "Among other things, they can learn to output a sorted list of symbols when their input consists of an unsorted sequence in which each symbol is accompanied by a real value that indicates its priority in the list\n",
            "Memory networks can be trained to keep track of the state of the world in a setting similar to a text adventure game and after reading a story, they can answer questions that require complex inference\n",
            "In one test example, the network is shown a 15-sentence version of the The Lord of the Rings and correctly answers questions such as “where is Frodo now?”.The future of deep learning Unsupervised learning had a catalytic effect in reviving interest in deep learning, but has since been overshadowed by the successes of purely supervised learning\n",
            "Although we have not focused on it in this Review, we expect unsupervised learning to become far more important in the longer term\n",
            "Human and animal learning is largely unsupervised:we discover the structure of the world by observing it, not by being told the name of every object.Human vision is an active process that sequentially samples the optic array in an intelligent, task-specific way using a small, high-resolution fovea with a large, low-resolution surround\n",
            "We expect much of the future progress in vision to come from systems that are trained end-to end and combine ConvNets with RNNs that use reinforcement learning to decide where to look\n",
            "Systems combining deep learning and reinforcement learning are in their infancy, but they already outperform passive vision systems at classification tasks and produce impressive results in learning to play many different video games\n",
            "Natural language understanding is another area in which deep learning is poised to make a large impact over the next few years\n",
            "We expect systems that use RNNs to understand sentences or whole documents will become much better when they learn strategies for selectively attending to one part at a time\n",
            "Ultimately, major progress in artificial intelligence will come about through systems that combine representation learning with complex reasoning\n",
            "Although deep learning and simple reasoning have been used for speech and handwriting recognition for a long time, new paradigms are needed to replace rule-based manipulation of symbolic expressions by operations on large vectors\n",
            "Indexes of top ranked_sentence order are  [(0.011957046367532963, ['Deep', 'learning', 'discovers', 'intricate', 'structure', 'in', 'large', 'data', 'sets', 'by', 'using', 'the', 'backpropagation', 'algorithm', 'to', 'indicate', 'how', 'a', 'machine', 'should', 'change', 'its', 'internal', 'parameters', 'that', 'are', 'used', 'to', 'compute', 'the', 'representation', 'in', 'each', 'layer', 'from', 'the', 'representation', 'in', 'the', 'previous', 'layer']), (0.010089803746484098, ['This', 'is', 'an', 'illustrative', 'example', 'with', 'only', 'two', 'input', 'units,', 'two', 'hidden', 'units', 'and', 'one', 'output', 'unit,', 'but', 'the', 'networks', 'used', 'for', 'object', 'recognition', 'or', 'natural', 'language', 'processing', 'contain', 'tens', 'or', 'hundreds', 'of', 'thousands', 'of', 'units']), (0.009981088301959479, ['The', 'key', 'aspect', 'of', 'deep', 'learning', 'is', 'that', 'these', 'layers', 'of', 'features', 'are', 'not', 'designed', 'by', 'human', 'engineers:', 'they', 'are', 'learned', 'from', 'data', 'using', 'a', 'general-purpose', 'learning', 'procedure']), (0.009934653164566936, ['Units', 'that', 'are', 'not', 'in', 'the', 'input', 'or', 'output', 'layer', 'are', 'conventionally', 'called', 'hidden', 'units']), (0.009648755134798863, ['New', 'learning', 'algorithms', 'and', 'architectures', 'that', 'are', 'currently', 'being', 'developed', 'for', 'deep', 'neural', 'networks', 'will', 'only', 'accelerate', 'this', 'progress.The', 'most', 'common', 'form', 'of', 'machine', 'learning,', 'deep', 'or', 'not,', 'is', 'supervised', 'learning']), (0.009329745915148503, ['Units', 'in', 'a', 'convolutional', 'layer', 'are', 'organized', 'in', 'feature', 'maps,', 'within', 'which', 'each', 'unit', 'is', 'connected', 'to', 'local', 'patches', 'in', 'the', 'feature', 'maps', 'of', 'the', 'previous', 'layer', 'through', 'a', 'set', 'of', 'weights', 'called', 'a', 'filter', 'bank']), (0.009281413878528906, ['In', 'a', 'language', 'model,the', 'other', 'layers', 'of', 'the', 'network', 'learn', 'to', 'convert', 'the', 'input', 'word', 'vectors', 'into', 'an', 'output', 'word', 'vector', 'for', 'the', 'predicted', 'next', 'word,', 'which', 'can', 'be', 'used', 'to', 'predict', 'the', 'probability', 'for', 'any', 'word', 'in', 'the', 'vocabulary', 'to', 'appear', 'as', 'the', 'next', 'word']), (0.00923616334538028, ['A', 'final', 'layer', 'of', 'output', 'units', 'could', 'then', 'be', 'added', 'to', 'the', 'top', 'of', 'the', 'network', 'and', 'the', 'whole', 'deep', 'system', 'could', 'be', 'fine-tuned', 'using', 'standard', 'backpropagation']), (0.009227410510138279, ['To', 'go', 'from', 'one', 'layer', 'to', 'the', 'next,', 'a', 'set', 'of', 'units', 'compute', 'a', 'weighted', 'sum', 'of', 'their', 'inputs', 'from', 'the', 'previous', 'layer', 'and', 'pass', 'the', 'result', 'through', 'a', 'non-linear', 'function']), (0.009125322130209536, ['Second,', 'composing', 'layers', 'of', 'representation', 'in', 'a', 'deep', 'net', 'brings', 'the', 'potential', 'for', 'another', 'exponential', 'advantage(exponential', 'in', 'the', 'depth).The', 'hidden', 'layers', 'of', 'a', 'multi', 'layer', 'neural', 'network', 'learn', 'to', 'represent', 'the', 'network’s', 'inputs', 'in', 'a', 'way', 'that', 'makes', 'it', 'easy', 'to', 'predict', 'the', 'target', 'outputs']), (0.009105151051360883, ['This', 'is', 'nicely', 'demonstrated', 'by', 'training', 'a', 'multi', 'layer', 'neural', 'network', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'sequence', 'from', 'a', 'local', 'context', 'of', 'earlier', 'words']), (0.008675122147864645, ['At', 'each', 'hidden', 'layer', 'we', 'compute', 'the', 'error', 'derivative', 'with', 'respect', 'to', 'the', 'output', 'of', 'each', 'unit,', 'which', 'is', 'a', 'weighted', 'sum', 'of', 'the', 'error', 'derivatives', 'with', 'respect', 'to', 'the', 'total', 'inputs', 'to', 'the', 'units', 'in', 'the', 'layer', 'above']), (0.008651705132675061, ['Systems', 'combining', 'deep', 'learning', 'and', 'reinforcement', 'learning', 'are', 'in', 'their', 'infancy,', 'but', 'they', 'already', 'outperform', 'passive', 'vision', 'systems', 'at', 'classification', 'tasks', 'and', 'produce', 'impressive', 'results', 'in', 'learning', 'to', 'play', 'many', 'different', 'video', 'games']), (0.008556294476852666, ['At', 'each', 'layer,', 'we', 'first', 'compute', 'the', 'total', 'input', 'z', 'to', 'each', 'unit,', 'which', 'is', 'a', 'weighted', 'sum', 'of', 'the', 'outputs', 'of', 'the', 'units', 'in', 'the', 'layer', 'below']), (0.008539909895615826, ['c,', 'The', 'equations', 'used', 'for', 'computing', 'the', 'forward', 'pass', 'in', 'a', 'neural', 'net', 'with', 'two', 'hidden', 'layers', 'and', 'one', 'output', 'layer,', 'each', 'constituting', 'a', 'module', 'through', 'which', 'one', 'can', 'backpropagate', 'gradients']), (0.008433355753722328, ['For', 'decades,', 'constructing', 'a', 'pattern-recognition', 'or', 'machine-learning', 'system', 'required', 'careful', 'engineering', 'and', 'considerable', 'domain', 'expertise', 'to', 'design', 'a', 'feature', 'extractor', 'that', 'transformed', 'the', 'raw', 'data', '(such', 'as', 'the', 'pixel', 'values', 'of', 'an', 'image)', 'into', 'a', 'suitable', 'internal', 'representation', 'or', 'feature', 'vector', 'from', 'which', 'the', 'learning', 'subsystem,', 'often', 'a', 'classifier,', 'could', 'detect', 'or', 'classify', 'patterns', 'in', 'the', 'input']), (0.00837681560097579, ['N-grams', 'treat', 'each', 'word', 'as', 'an', 'atomic', 'unit,', 'so', 'they', 'cannot', 'generalize', 'across', 'semantically', 'related', 'sequences', 'of', 'words,', 'whereas', 'neural', 'language', 'models', 'can', 'because', 'they', 'associate', 'each', 'word', 'with', 'a', 'vector', 'of', 'real', 'valued', 'features,', 'and', 'semantically', 'related', 'words', 'end', 'up', 'close', 'to', 'each', 'other', 'in', 'that', 'vector', 'space.Recurrent', 'neural', 'networks', 'When', 'backpropagation', 'was', 'first', 'introduced,', 'its', 'most', 'exciting', 'use', 'was', 'for', 'training', 'recurrent', 'neural', 'networks', '(RNNs)']), (0.008344864920682177, ['The', 'network', 'learns', 'word', 'vectors', 'that', 'contain', 'many', 'active', 'components', 'each', 'of', 'which', 'can', 'be', 'interpreted', 'as', 'a', 'separate', 'feature', 'of', 'the', 'word,', 'as', 'was', 'first', 'demonstrated', 'in', 'the', 'context', 'of', 'learning', 'distributed', 'representations', 'for', 'symbols']), (0.008289073308768305, ['A', 'typical', 'pooling', 'unit', 'computes', 'the', 'maximum', 'of', 'a', 'local', 'patch', 'of', 'units', 'in', 'one', 'feature', 'map', '(or', 'in', 'a', 'few', 'feature', 'maps).Neighbouring', 'pooling', 'units', 'take', 'input', 'from', 'patches', 'that', 'are', 'shifted', 'by', 'more', 'than', 'one', 'row', 'or', 'column,', 'thereby', 'reducing', 'the', 'dimension', 'of', 'the', 'representation', 'and', 'creating', 'an', 'invariance', 'to', 'small', 'shifts', 'and', 'distortions']), (0.00828142877436452, ['Once', 'these', 'gradients', 'have', 'been', 'computed,', 'it', 'is', 'straightforward', 'to', 'compute', 'the', 'gradients', 'with', 'respect', 'to', 'the', 'weights', 'of', 'each', 'module.Many', 'applications', 'of', 'deep', 'learning', 'use', 'feedforward', 'neural', 'network', 'architectures,', 'which', 'learn', 'to', 'map', 'a', 'fixed-size', 'input(for', 'example,', 'an', 'image)', 'to', 'a', 'fixed-size', 'output', '(for', 'example,', 'a', 'probability', 'for', 'each', 'of', 'several', 'categories)']), (0.008145897119303046, ['For', 'example,', 'after', 'reading', 'an', 'English', 'sentence', 'one', 'word', 'at', 'a', 'time,', 'an', 'English', '‘encoder’', 'network', 'can', 'be', 'trained', 'so', 'that', 'the', 'final', 'state', 'vector', 'of', 'its', 'hidden', 'units', 'is', 'a', 'good', 'representation', 'of', 'the', 'thought', 'expressed', 'by', 'the', 'sentence']), (0.008140668931334949, ['In', 'one', 'test', 'example,', 'the', 'network', 'is', 'shown', 'a', '15-sentence', 'version', 'of', 'the', 'The', 'Lord', 'of', 'the', 'Rings', 'and', 'correctly', 'answers', 'questions', 'such', 'as', '“where', 'is', 'Frodo', 'now?”.The', 'future', 'of', 'deep', 'learning', 'Unsupervised', 'learning', 'had', 'a', 'catalytic', 'effect', 'in', 'reviving', 'interest', 'in', 'deep', 'learning,', 'but', 'has', 'since', 'been', 'overshadowed', 'by', 'the', 'successes', 'of', 'purely', 'supervised', 'learning']), (0.008125001977802079, ['ConvNets', 'have', 'their', 'roots', 'in', 'the', 'neocognitron,the', 'architecture', 'of', 'which', 'was', 'somewhat', 'similar,', 'but', 'did', 'not', 'have', 'an', 'end-to-end', 'supervised-learning', 'algorithm', 'such', 'as', 'backpropagation.A', 'primitive', '1D', 'ConvNet', 'called', 'a', 'time-delay', 'neural', 'net', 'was', 'used', 'for', 'the', 'recognition', 'of', 'phonemes', 'and', 'simple', 'words.There', 'have', 'been', 'numerous', 'applications', 'of', 'convolutional', 'networks', 'going', 'back', 'to', 'the', 'early', '1990s,', 'starting', 'with', 'time-delay', 'neural', 'networks', 'for', 'speech', 'recognition', 'and', 'document', 'reading']), (0.008112540032236402, ['A', 'linear', 'classifier,', 'or', 'any', 'other', '‘shallow’', 'classifier', 'operating', 'on', '', 'A', 'multi', 'layer', 'neural', 'network', 'can', 'distort', 'the', 'input', 'space', 'to', 'make', 'the', 'classes', 'of', 'data', 'linearly', 'separable']), (0.00799981735097797, ['At', 'present,', 'the', 'most', 'popular', 'non-linear', 'function', 'is', 'the', 'rectified', 'linear', 'unit', '(ReLU),', 'which', 'is', 'simply', 'the', 'half-wave', 'rectifier', 'f(z)=', 'max(z,', '0).In', 'past', 'decades,', 'neural', 'nets', 'used', 'smoother', 'non-linearities,', 'such', 'as', 'tanh(z)', 'or', '1/(1+exp(−z)),', 'but', 'the', 'ReLU', 'typically', 'learns', 'much', 'faster', 'in', 'networks', 'with', 'many', 'layers,', 'allowing', 'training', 'of', 'a', 'deep', 'supervised', 'network', 'without', 'unsupervised', 'pre-training']), (0.007970278997130851, ['The', 'objective', 'in', 'learning', 'each', 'layer', 'of', 'feature', 'detectors', 'was', 'to', 'be', 'able', 'to', 'reconstructor', 'model', 'the', 'activities', 'of', 'feature', 'detectors', '(or', 'raw', 'inputs)', 'in', 'the', 'layer', 'below']), (0.00794224007254109, ['When', 'we', 'consider', 'the', 'outputs', 'of', 'the', 'hidden', 'units', 'at', 'different', 'discrete', 'time', 'steps', 'as', 'if', 'they', 'were', 'the', 'outputs', 'of', 'different', 'neurons', 'in', 'a', 'deep', 'multi', 'layer', 'network,', 'it', 'becomes', 'clear', 'how', 'we', 'can', 'apply', 'backpropagation', 'to', 'train', 'RNNs']), (0.007891653861496942, ['Deep', 'learning', 'allows', 'computational', 'models', 'that', 'are', 'composed', 'of', 'multiple', 'processing', 'layers', 'to', 'learn', 'representations', 'of', 'data', 'with', 'multiple', 'levels', 'of', 'abstraction']), (0.007827470741021667, ['Increasingly,', 'these', 'applications', 'make', 'use', 'of', 'a', 'class', 'of', 'techniques', 'called', 'deep', 'learning']), (0.007749551625129768, ['Mathematically,', 'the', 'filtering', 'operation', 'performed', 'by', 'a', 'feature', 'map', 'is', 'a', 'discrete', 'convolution,', 'hence', 'the', 'name.Although', 'the', 'role', 'of', 'the', 'convolutional', 'layer', 'is', 'to', 'detect', 'local', 'conjunctions', 'of', 'features', 'from', 'the', 'previous', 'layer,', 'the', 'role', 'of', 'the', 'pooling', 'layer', 'is', 'to', 'merge', 'semantically', 'similar', 'features', 'into', 'one']), (0.007721737099706456, ['Representation', 'learning', 'is', 'a', 'set', 'of', 'methods', 'that', 'allows', 'a', 'machine', 'to', 'be', 'fed', 'with', 'raw', 'data', 'and', 'to', 'automatically', 'discover', 'the', 'representations', 'needed', 'for', 'detection', 'or', 'classification']), (0.007684297879206214, ['Backpropagating', 'gradients', 'through', 'a', 'ConvNet', 'is', 'as', 'simple', 'as', 'through', 'a', 'regular', 'deep', 'network,', 'allowing', 'all', 'the', 'weights', 'in', 'all', 'the', 'filter', 'banks', 'to', 'be', 'trained.Deep', 'neural', 'networks', 'exploit', 'the', 'property', 'that', 'many', 'natural', 'signals', 'are', 'compositional', 'hierarchies,', 'in', 'which', 'higher-level', 'features', 'are', 'obtained', 'by', 'composing', 'lower-level', 'ones']), (0.007671958900979411, ['Many', 'of', 'the', 'current', 'practical', 'applications', 'of', 'machine', 'learning', 'use', 'linear', 'classifiers', 'on', 'top', 'of', 'hand-engineered', 'features']), (0.007627141588188756, ['As', 'it', 'turns', 'out,', 'multi', 'layer', 'architectures', 'can', 'be', 'trained', 'by', 'simple', 'stochastic', 'gradient', 'descent.As', 'long', 'as', 'the', 'modules', 'are', 'relatively', 'smooth', 'functions', 'of', 'their', 'inputs', 'and', 'of', 'their', 'internal', 'weights,', 'one', 'can', 'compute', 'gradients', 'using', 'the', 'backpropagation', 'procedure']), (0.0074727666586027865, ['This', 'thought', 'vector', 'can', 'then', 'be', 'used', 'as', 'the', 'initial', 'hidden', 'state', 'of', '(or', 'as', 'extra', 'input', 'to)', 'a', 'jointly', 'trained', 'French', '‘decoder’', 'network,', 'which', 'outputs', 'a', 'probability', 'distribution', 'for', 'the', 'first', 'word', 'of', 'the', 'French', 'translation']), (0.007408565070109364, ['By', '‘pre-training’', 'several', 'layers', 'of', 'progressively', 'more', 'complex', 'feature', 'detectors', 'using', 'this', 'reconstruction', 'objective,', 'the', 'weights', 'of', 'a', 'deep', 'network', 'could', 'be', 'initialized', 'to', 'sensible', 'values']), (0.007394422384263066, ['It', 'achieved', 'many', 'practical', 'successes', 'during', 'the', 'period', 'when', 'neural', 'networks', 'were', 'out', 'of', 'favour', 'and', 'it', 'has', 'recently', 'been', 'widely', 'adopted', 'by', 'the', 'computer', 'vision', 'community.Convolutional', 'neural', 'networks', 'ConvNets', 'are', 'designed', 'to', 'process', 'data', 'that', 'come', 'in', 'the', 'form', 'of', 'multiple', 'arrays,', 'for', 'example', 'a', 'colour', 'image', 'composed', 'of', 'three', '2Darrays', 'containing', 'pixel', 'intensities', 'in', 'the', 'three', 'colour', 'channels']), (0.0073412455426854276, ['This', 'is', 'the', 'key', 'advantage', 'of', 'deep', 'learning.A', 'deep-learning', 'architecture', 'is', 'a', 'multi', 'layer', 'stack', 'of', 'simple', 'modules,', 'all', '(or', 'most)', 'of', 'which', 'are', 'subject', 'to', 'learning,', 'and', 'many', 'of', 'which', 'compute', 'non-linear', 'input–output', 'mappings']), (0.007315010398966441, ['The', 'researchers', 'introduced', 'unsupervised', 'learning', 'procedures', 'that', 'could', 'create', 'layers', 'of', 'feature', 'detectors', 'without', 'requiring', 'labelled', 'data']), (0.007276564318564589, ['The', 'encoder', 'here', 'is', 'a', 'deep', 'ConvNet', 'that', 'converts', 'the', 'pixels', 'into', 'an', 'activity', 'vector', 'in', 'its', 'last', 'hidden', 'layer']), (0.0072708543905372755, ['LSTM', 'networks', 'or', 'related', 'forms', 'of', 'gated', 'units', 'are', 'also', 'currently', 'used', 'for', 'the', 'encoder', 'and', 'decoder', 'networks', 'that', 'perform', 'so', 'well', 'at', 'machine', 'translation.Over', 'the', 'past', 'year,', 'several', 'authors', 'have', 'made', 'different', 'proposals', 'to', 'augment', 'RNNs', 'with', 'a', 'memory', 'module']), (0.007220888688679558, ['The', 'idea', 'that', 'this', 'could', 'be', 'done,', 'and', 'that', 'it', 'worked,', 'was', 'discovered', 'independently', 'by', 'several', 'different', 'groups', 'during', 'the', '1970s', 'and', '1980s.The', 'backpropagation', 'procedure', 'to', 'compute', 'the', 'gradient', 'of', 'an', 'objective', 'function', 'with', 'respect', 'to', 'the', 'weights', 'of', 'a', 'multi', 'layer', 'stack', 'of', 'modules', 'is', 'nothing', 'more', 'than', 'a', 'practical', 'application', 'of', 'the', 'chain', 'rule', 'for', 'derivatives']), (0.007219707758494489, ['These', 'word', 'vectors', 'are', 'composed', 'of', 'learned', 'features', 'that', 'were', 'not', 'determined', 'ahead', 'of', 'time', 'by', 'experts,', 'but', 'automatically', 'discovered', 'by', 'the', 'neural', 'network']), (0.0072095351566665265, ['If', 'a', 'particular', 'first', 'word', 'is', 'chosen', 'from', 'this', 'distribution', 'and', 'provided', 'as', 'input', 'to', 'the', 'decoder', 'network', 'it', 'will', 'then', 'output', 'a', 'probability', 'distribution', 'for', 'the', 'second', 'word', 'of', 'the', 'translation', 'and', 'so', 'on', 'until', 'a', 'full', 'stop', 'is', 'chosen']), (0.00717860931787373, ['Different', 'feature', 'maps', 'in', 'a', 'layer', 'use', 'different', 'filter', 'banks']), (0.00714015702202662, ['Natural', 'language', 'understanding', 'is', 'another', 'area', 'in', 'which', 'deep', 'learning', 'is', 'poised', 'to', 'make', 'a', 'large', 'impact', 'over', 'the', 'next', 'few', 'years']), (0.00713299714409974, ['They', 'were', 'discovered', 'by', 'the', 'learning', 'procedure', 'as', 'a', 'good', 'way', 'of', 'factorizing', 'the', 'structured', 'relationships', 'between', 'the', 'input', 'and', 'output', 'symbols', 'into', 'multiple', '‘micro-rules’']), (0.007110758845865289, ['Beyond', 'simple', 'memorization,', 'neural', 'Turing', 'machines', 'and', 'memory', 'networks', 'are', 'being', 'used', 'for', 'tasks', 'that', 'would', 'normally', 'require', 'reasoning', 'and', 'symbol', 'manipulation']), (0.007086175534221045, ['A', 'number', 'of', 'companies', 'such', 'as', 'NVIDIA,', 'Mobileye,', 'Intel,', 'Qualcomm', 'and', 'Samsung', 'are', 'developing', 'ConvNet', 'chips', 'to', 'enable', 'real-time', 'vision', 'applications', 'in', 'smartphones,', 'cameras,', 'robots', 'and', 'self-driving', 'cars.Distributed', 'representations', 'and', 'language', 'processing', 'Deep-learning', 'theory', 'shows', 'that', 'deep', 'nets', 'have', 'two', 'different', 'exponential', 'advantages', 'over', 'classic', 'learning', 'algorithms', 'that', 'do', 'not', 'use', 'distributed', 'representations']), (0.007008216986735625, ['When', 'deep', 'convolutional', 'networks', 'were', 'applied', 'to', 'a', 'data', 'set', 'of', 'about', 'a', 'million', 'images', 'from', 'the', 'web', 'that', 'contained', '1,000', 'different', 'classes,', 'they', 'achieved', 'spectacular', 'results,', 'almost', 'halving', 'the', 'error', 'rates', 'of', 'the', 'best', 'competing', 'approaches']), (0.006667436625479388, ['We', 'think', 'that', 'deep', 'learning', 'will', 'have', 'many', 'more', 'successes', 'in', 'the', 'near', 'future', 'because', 'it', 'requires', 'very', 'little', 'engineering', 'by', 'hand,', 'so', 'it', 'can', 'easily', 'take', 'advantage', 'of', 'increases', 'in', 'the', 'amount', 'of', 'available', 'computation', 'and', 'data']), (0.006645909806711059, ['There', 'has', 'been', 'a', 'surge', 'of', 'interest', 'in', 'such', 'systems', 'recently.RNNs,', 'once', 'unfolded', 'in', 'time,', 'can', 'be', 'seen', 'as', 'very', 'deep', 'feedforward', 'networks', 'in', 'which', 'all', 'the', 'layers', 'share', 'the', 'same', 'weights.Although', 'their', 'main', 'purpose', 'is', 'to', 'learn', 'long-term', 'dependencies,theoretical', 'and', 'empirical', 'evidence', 'shows', 'that', 'it', 'is', 'difficult', 'to', 'learn', 'to', 'store', 'information', 'for', 'very', 'long.To', 'correct', 'for', 'that,', 'one', 'idea', 'is', 'to', 'augment', 'the', 'network', 'with', 'an', 'explicit', 'memory']), (0.0066315224552860605, ['ConvNets', 'were', 'also', 'experimented', 'with', 'in', 'the', 'early', '1990s', 'for', 'object', 'detection', 'in', 'natural', 'images,', 'including', 'faces', 'and', 'hands,and', 'for', 'face', 'recognition.Image', 'understanding', 'with', 'deep', 'convolutional', 'networks', 'Since', 'the', 'early', '2000s,', 'ConvNets', 'have', 'been', 'applied', 'with', 'great', 'success', 'to', 'the', 'detection,', 'segmentation', 'and', 'recognition', 'of', 'objects', 'and', 'regions', 'in', 'images']), (0.006570768170283333, ['But', 'this', 'can', 'all', 'be', 'avoided', 'if', 'good', 'features', 'can', 'be', 'learned', 'automatically', 'using', 'a', 'general-purpose', 'learning', 'procedure']), (0.006543290290874566, ['RNNs', 'are', 'very', 'powerful', 'dynamic', 'systems,', 'but', 'training', 'them', 'has', 'proved', 'to', 'be', 'problematic', 'because', 'the', 'backpropagated', 'gradients', 'either', 'grow', 'or', 'shrink', 'at', 'each', 'time', 'step,', 'so', 'over', 'many', 'time', 'steps', 'they', 'typically', 'explode', 'or', 'vanish.Thanks', 'to', 'advances', 'in', 'their', 'architecture', 'and', 'ways', 'of', 'training', 'them,', 'RNNs', 'have', 'been', 'found', 'to', 'be', 'very', 'good', 'at', 'predicting', 'the', 'next', 'character', 'in', 'the', 'text', 'or', 'the', 'next', 'word', 'in', 'a', 'sequence,', 'but', 'they', 'can', 'also', 'be', 'used', 'for', 'more', 'complex', 'tasks']), (0.006534228361559547, ['Once', 'deeplearning', 'had', 'been', 'rehabilitated,', 'it', 'turned', 'out', 'that', 'the', 'pre-training', 'stage', 'was', 'only', 'needed', 'for', 'small', 'data', 'sets.There', 'was,', 'however,', 'one', 'particular', 'type', 'of', 'deep,', 'feedforward', 'network', 'that', 'was', 'much', 'easier', 'to', 'train', 'and', 'generalized', 'much', 'better', 'than', 'networks', 'with', 'full', 'connectivity', 'between', 'adjacent', 'layers']), (0.006507959543813236, ['Learning', 'word', 'vectors', 'turned', 'out', 'to', 'also', 'work', 'very', 'well', 'when', 'the', 'word', 'sequences', 'come', 'from', 'a', 'large', 'corpus', 'of', 'real', 'text', 'and', 'the', 'individual', 'micro-rules', 'are', 'unreliable']), (0.006505992778318776, ['The', 'decoder', 'is', 'an', 'RNN', 'similar', 'to', 'the', 'ones', 'used', 'for', 'machine', 'translation', 'and', 'neural', 'language', 'modelling']), (0.006505648089462066, ['During', 'training,', 'the', 'machine', 'is', 'shown', 'an', 'image', 'and', 'produces', 'an', 'output', 'in', 'the', 'form', 'of', 'a', 'vector', 'of', 'scores,', 'one', 'for', 'each', 'category']), (0.006410732558022483, ['The', 'hidden', 'layers', 'can', 'be', 'seen', 'as', 'distorting', 'the', 'input', 'in', 'a', 'non-linear', 'way', 'so', 'that', 'categories', 'become', 'linearly', 'separable', 'by', 'the', 'last', 'layer.In', 'the', 'late', '1990s,', 'neural', 'nets', 'and', 'backpropagation', 'were', 'largely', 'forsaken', 'by', 'the', 'machine-learning', 'community', 'and', 'ignored', 'by', 'the', 'computer-vision', 'and', 'speech-recognition', 'communities']), (0.006317846751871159, ['An', 'image,', 'for', 'example,', 'comes', 'in', 'the', 'form', 'of', 'an', 'array', 'of', 'pixel', 'values,', 'and', 'the', 'learned', 'features', 'in', 'the', 'first', 'layer', 'of', 'representation', 'typically', 'represent', 'the', 'presence', 'or', 'absence', 'of', 'edges', 'at', 'particular', 'orientations', 'and', 'locations', 'in', 'the', 'image']), (0.006251529038481827, ['The', 'process', 'is', 'repeated', 'for', 'many', 'small', 'sets', 'of', 'examples', 'from', 'the', 'training', 'set', 'until', 'the', 'average', 'of', 'the', 'objective', 'function', 'stops', 'decreasing']), (0.006096213447760671, ['By', 'contrast,', 'neural', 'networks', 'just', 'use', 'big', 'activity', 'vectors,', 'big', 'weight', 'matrices', 'and', 'scalar', 'non-linearities', 'to', 'perform', 'the', 'type', 'of', 'fast', '‘intuitive’', 'inference', 'that', 'underpins', 'effortless', 'commonsense', 'reasoning.Before', 'the', 'introduction', 'of', 'neural', 'language', 'models,', 'the', 'standard', 'approach', 'to', 'statistical', 'modelling', 'of', 'language', 'did', 'not', 'exploit', 'distributed', 'representations:', 'it', 'was', 'based', 'on', 'counting', 'frequencies', 'of', 'occurrences', 'of', 'short', 'symbol', 'sequences', 'of', 'length', 'up', 'to', 'N', '(called', 'N-grams).The', 'number', 'of', 'possible', 'N-grams', 'is', 'on', 'the', 'order', 'of', 'VN,', 'where', 'V', 'is', 'the', 'vocabulary', 'size,', 'so', 'taking', 'into', 'account', 'a', 'context', 'of', 'more', 'than', 'a', 'handful', 'of', 'words', 'would', 'require', 'very', 'large', 'training', 'corpora']), (0.0060713929300345105, ['Vector', 'representations', 'of', 'words', 'learned', 'from', 'text', 'are', 'now', 'very', 'widely', 'used', 'in', 'natural', 'language', 'applications.The', 'issue', 'of', 'representation', 'lies', 'at', 'the', 'heart', 'of', 'the', 'debate', 'between', 'the', 'logic-inspired', 'and', 'the', 'neural-network-inspired', 'paradigms', 'for', 'cognition']), (0.0060693061517983656, ['We', 'expect', 'much', 'of', 'the', 'future', 'progress', 'in', 'vision', 'to', 'come', 'from', 'systems', 'that', 'are', 'trained', 'end-to', 'end', 'and', 'combine', 'ConvNets', 'with', 'RNNs', 'that', 'use', 'reinforcement', 'learning', 'to', 'decide', 'where', 'to', 'look']), (0.00603977922625896, ['This', 'was', 'the', 'convolutional', 'neural', 'network', '(ConvNet)']), (0.006028370949273722, ['This', 'is', 'why', 'shallow', 'classifiers', 'require', 'a', 'good', 'feature', 'extractor', 'that', 'solves', 'the', 'selectivity–invariance', 'dilemma', '—', 'one', 'that', 'produces', 'representations', 'that', 'are', 'selective', 'to', 'the', 'aspects', 'of', 'the', 'image', 'that', 'are', 'important', 'for', 'discrimination,', 'but', 'that', 'are', 'invariant', 'to', 'irrelevant', 'aspects', 'such', 'as', 'the', 'pose', 'of', 'the', 'animal.To', 'make', 'classifiers', 'more', 'powerful,', 'one', 'can', 'use', 'generic', 'non-linear', 'features,', 'as', 'with', 'kernel', 'methods,', 'but', 'generic', 'features', 'such', 'as', 'those', 'arising', 'with', 'the', 'Gaussian', 'kernel', 'do', 'not', 'allow', 'the', 'learner', 'to', 'generalize', 'well', 'far', 'from', 'the', 'training', 'examples']), (0.005916379142368342, ['In', 'the', 'first', 'layer,', 'each', 'word', 'creates', 'a', 'different', 'pattern', 'of', 'activations,', 'or', 'word', 'vectors']), (0.00583278609594505, ['We', 'then', 'convert', 'the', 'error', 'derivative', 'with', 'respect', 'to', 'the', 'output', 'into', 'the', 'error', 'derivative', 'with', 'respect', 'to', 'the', 'input', 'by', 'multiplying', 'it', 'by', 'the', 'gradient', 'of', 'f(z).At', 'the', 'output', 'layer,', 'the', 'error', 'derivative', 'with', 'respect', 'to', 'the', 'output', 'of', 'a', 'unit', 'is', 'computed', 'by', 'differentiating', 'the', 'cost', 'function']), (0.0058038904695278705, ['Deep', 'learning', 'is', 'making', 'major', 'advances', 'in', 'solving', 'problems', 'that', 'have', 'resisted', 'the', 'best', 'attempts', 'of', 'the', 'artificial', 'intelligence', 'community', 'for', 'many', 'years']), (0.005777661080404841, ['Deep', 'convolutional', 'nets', 'have', 'brought', 'about', 'breakthroughs', 'in', 'processing', 'images,', 'video,', 'speech', 'and', 'audio,', 'whereas', 'recurrent', 'nets', 'have', 'shone', 'light', 'on', 'sequential', 'data', 'such', 'as', 'text', 'and', 'speech.Machine-learning', 'technology', 'powers', 'many', 'aspects', 'of', 'modern', 'society', 'from', 'web', 'searches', 'to', 'content', 'filtering', 'on', 'social', 'networks', 'to', 'recommendations', 'on', 'e-commerce', 'websites,', 'and', 'it', 'is', 'increasingly', 'present', 'in', 'consumer', 'products', 'such', 'as', 'cameras', 'and', 'smartphones']), (0.005776455940110371, ['Note', 'how', 'a', 'regular', 'grid', 'in', 'input', 'space', 'is', 'also', 'transformed', 'by', 'hidden', 'units']), (0.005772539837836221, ['In', 'particular,', 'it', 'was', 'commonly', 'thought', 'that', 'simple', 'gradient', 'descent', 'would', 'get', 'trapped', 'in', 'poor', 'local', 'minima', '—', 'weight', 'configurations', 'for', 'which', 'no', 'small', 'change', 'would', 'reduce', 'the', 'average', 'error.In', 'practice,', 'poor', 'local', 'minima', 'are', 'rarely', 'a', 'problem', 'with', 'large', 'networks']), (0.005769775491491644, ['Perhaps', 'more', 'surprisingly,', 'deep', 'learning', 'has', 'produced', 'extremely', 'promising', 'results', 'for', 'various', 'tasks', 'in', 'natural', 'language', 'understanding,', 'particularly', 'topic', 'classification,', 'sentiment', 'analysis,', 'question', 'answering', 'and', 'language', 'translation']), (0.0057029618196604015, ['For', 'simplicity,', 'we', 'have', 'omitted', 'bias', 'terms.The', 'non-linear', 'functions', 'used', 'in', 'neural', 'networks', 'include', 'the', 'rectified', 'linear', 'unit', '(ReLU)', 'f(z)', '=', 'max(0,z),', 'commonly', 'used', 'in', 'recent', 'years,', 'aswell', 'as', 'the', 'more', 'conventional', 'sigmoids,', 'such', 'as', 'the', 'hyberbolic', 'tangent,f(z)', '=(exp(z)−', 'exp(−z))/(exp(z)+exp(−z))', 'and', 'logistic', 'function', 'logistic,f(z)', '=1/(1', '+', 'exp(−z))']), (0.005702618067375289, ['The', 'first', 'proposal', 'of', 'this', 'kind', 'is', 'the', 'long', 'short-term', 'memory', '(LSTM)', 'networks', 'that', 'use', 'special', 'hidden', 'units,', 'the', 'natural', 'behaviour', 'of', 'which', 'is', 'to', 'remember', 'inputs', 'for', 'a', 'long', 'time']), (0.005660535320560063, ['The', 'key', 'insight', 'is', 'that', 'the', 'derivative', '(or', 'gradient)', 'of', 'the', 'objective', 'with', 'respect', 'to', 'the', 'input', 'of', 'a', 'module', 'can', 'be', 'computed', 'by', 'working', 'backwards', 'from', 'the', 'gradient', 'with', 'respect', 'to', 'the', 'output', 'of', 'that', 'module', '(or', 'the', 'input', 'of', 'the', 'subsequent', 'module)']), (0.0056505523767939846, ['We', 'first', 'collect', 'a', 'large', 'data', 'set', 'of', 'images', 'of', 'houses,', 'cars,', 'people', 'and', 'pets,', 'each', 'labelled', 'with', 'its', 'category']), (0.005640096537044343, ['Backpropagation', 'to', 'train', 'multi', 'layer', 'architectures']), (0.005610176133830378, ['RNNs', 'process', 'an', 'input', 'sequence', 'one', 'element', 'at', 'a', 'time,', 'maintaining', 'in', 'their', 'hidden', 'units', 'a', '‘state', 'vector’', 'that', 'implicitly', 'contains', 'information', 'about', 'the', 'history', 'of', 'all', 'the', 'past', 'elements', 'of', 'the', 'sequence']), (0.005578760903698353, ['The', 'first', 'few', 'stages', 'are', 'composed', 'of', 'two', 'types', 'of', 'layers:', 'convolutional', 'layers', 'and', 'pooling', 'layers']), (0.005570508648479432, ['Ultimately,', 'major', 'progress', 'in', 'artificial', 'intelligence', 'will', 'come', 'about', 'through', 'systems', 'that', 'combine', 'representation', 'learning', 'with', 'complex', 'reasoning']), (0.0055644719883557155, ['There', 'are', 'four', 'key', 'ideas', 'behind', 'ConvNets', 'that', 'take', 'advantage', 'of', 'the', 'properties', 'of', 'natural', 'signals:', 'local', 'connections,', 'shared', 'weights,', 'pooling', 'and', 'the', 'use', 'of', 'many', 'layers.The', 'architecture', 'of', 'a', 'typical', 'ConvNet', 'is', 'structured', 'as', 'a', 'series', 'of', 'stages']), (0.005544936648613518, ['In', 'a', 'typical', 'deep-learning', 'system,', 'there', 'may', 'be', 'hundreds', 'of', 'millions', 'of', 'these', 'adjustable', 'weights,', 'and', 'hundreds', 'of', 'millions', 'of', 'labelled', 'examples', 'with', 'which', 'to', 'train', 'the', 'machine.To', 'properly', 'adjust', 'the', 'weight', 'vector,', 'the', 'learning', 'algorithm', 'computes', 'a', 'gradient', 'vector', 'that,', 'for', 'each', 'weight,', 'indicates', 'by', 'what', 'amount', 'the', 'error', 'would', 'increase', 'or', 'decrease', 'if', 'the', 'weight', 'were', 'increased', 'by', 'a', 'tiny', 'amount']), (0.005480325146849778, ['After', 'training,', 'the', 'performance', 'of', 'the', 'system', 'is', 'measured', 'on', 'a', 'different', 'set', 'of', 'examples', 'called', 'a', 'test', 'set']), (0.005473591309047925, ['LSTM', 'networks', 'have', 'subsequently', 'proved', 'to', 'be', 'more', 'effective', 'than', 'conventional', 'RNNs,', 'especially', 'when', 'they', 'have', 'several', 'layers', 'for', 'each', 'time', 'step,', 'enabling', 'an', 'entire', 'speech', 'recognition', 'system', 'that', 'goes', 'all', 'the', 'way', 'from', 'acoustics', 'to', 'the', 'sequence', 'of', 'characters', 'in', 'the', 'transcription']), (0.005350466478214092, ['A', 'two-class', 'linear', 'classifier', 'computes', 'a', 'weighted', 'sum', 'of', 'the', 'feature', 'vector', 'components.If', 'the', 'weighted', 'sum', 'is', 'above', 'a', 'threshold,', 'the', 'input', 'is', 'classified', 'as', 'belonging', 'to', 'a', 'particular', 'category']), (0.005338058784569858, ['This', 'worked', 'remarkably', 'well', 'for', 'recognizing', 'handwritten', 'digits', 'or', 'for', 'detecting', 'pedestrians,', 'especially', 'when', 'the', 'amount', 'of', 'labelled', 'data', 'was', 'very', 'limited.The', 'first', 'major', 'application', 'of', 'this', 'pre-training', 'approach', 'was', 'inspeech', 'recognition,', 'and', 'it', 'was', 'made', 'possible', 'by', 'the', 'advent', 'of', 'fast', 'graphics', 'processing', 'units', '(GPUs)', 'that', 'were', 'convenient', 'to', 'program', 'and', 'allowed', 'researchers', 'to', 'train', 'networks', '10', 'or', '20', 'times', 'faster']), (0.00532718212803165, ['The', 'pooling', 'allows', 'representations', 'to', 'vary', 'very', 'little', 'when', 'elements', 'in', 'the', 'previous', 'layer', 'vary', 'in', 'position', 'and', 'appearance.The', 'convolutional', 'and', 'pooling', 'layers', 'in', 'ConvNets', 'are', 'directly', 'inspired', 'by', 'the', 'classic', 'notions', 'of', 'simple', 'cells', 'and', 'complex', 'cells', 'in', 'visual', 'neuroscience,', 'and', 'the', 'overall', 'architecture', 'is', 'reminiscent', 'of', 'the', 'LGN–V1–V2–V4–IT', 'hierarchy', 'in', 'the', 'visual', 'cortex', 'ventral', 'pathway']), (0.005294357079899626, ['Such', 'representations', 'are', 'called', 'distributed', 'representations', 'because', 'their', 'elements', '(the', 'features)', 'are', 'not', 'mutually', 'exclusive', 'and', 'their', 'many', 'configurations', 'correspond', 'to', 'the', 'variations', 'seen', 'in', 'the', 'observed', 'data']), (0.0052644318845285224, ['Proposals', 'include', 'the', 'Neural', 'Turing', 'Machine', 'in', 'which', 'the', 'network', 'is', 'augmented', 'by', 'a', '‘tape-like’memory', 'that', 'the', 'RNN', 'can', 'choose', 'to', 'read', 'from', 'or', 'write', 'to,', 'and', 'memory', 'networks,', 'in', 'which', 'a', 'regular', 'network', 'is', 'augmented', 'by', 'a', 'kind', 'of', 'associative', 'memory']), (0.005230526917390387, ['Conventional', 'machine-learning', 'techniques', 'were', 'limited', 'in', 'their', 'ability', 'to', 'process', 'natural', 'data', 'in', 'their', 'raw', 'form']), (0.005223192633943946, ['Whereas', 'training', 'such', 'large', 'networks', 'could', 'have', 'taken', 'weeks', 'only', 'two', 'years', 'ago,', 'progress', 'in', 'hardware,', 'software', 'and', 'algorithm', 'parallelization', 'have', 'reduced', 'training', 'times', 'to', 'a', 'few', 'hours.The', 'performance', 'of', 'ConvNet-based', 'vision', 'systems', 'has', 'caused', 'most', 'major', 'technology', 'companies,', 'including', 'Google,', 'Facebook,', 'Microsoft,', 'IBM,', 'Yahoo!,', 'Twitter', 'and', 'Adobe,', 'as', 'well', 'as', 'a', 'quickly', 'growing', 'number', 'of', 'start-ups', 'to', 'initiate', 'research', 'and', 'development', 'projects', 'and', 'to', 'deploy', 'ConvNet-based', 'image', 'understanding', 'products', 'and', 'services']), (0.005196015690539087, ['In', 'other', 'words,', 'if', 'a', 'motifcan', 'appear', 'in', 'one', 'part', 'of', 'the', 'image,', 'it', 'could', 'appear', 'anywhere,', 'hence', 'the', 'idea', 'of', 'units', 'at', 'different', 'locations', 'sharing', 'the', 'same', 'weights', 'and', 'detecting', 'the', 'same', 'pattern', 'in', 'different', 'parts', 'of', 'the', 'array']), (0.005131394455203148, ['When', 'trained', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'news', 'story,', 'for', 'example,', 'the', 'learned', 'word', 'vectors', 'for', 'Tuesday', 'and', 'Wednesday', 'are', 'very', 'similar,', 'as', 'are', 'the', 'word', 'vectors', 'for', 'Sweden', 'and', 'Norway']), (0.005085686772320548, ['The', 'backpropagation', 'equation', 'can', 'be', 'applied', 'repeatedly', 'to', 'propagate', 'gradients', 'through', 'all', 'modules,', 'starting', 'from', 'the', 'output', 'at', 'the', 'top', '(where', 'the', 'network', 'produces', 'its', 'prediction)', 'all', 'the', 'way', 'to', 'the', 'bottom', '(where', 'the', 'external', 'input', 'is', 'fed)']), (0.0050530411246810245, ['The', 'negative', 'gradient', 'vector', 'indicates', 'the', 'direction', 'of', 'steepest', 'descent', 'in', 'this', 'landscape,', 'taking', 'it', 'closer', 'to', 'a', 'minimum,', 'where', 'the', 'output', 'error', 'is', 'low', 'on', 'average.In', 'practice,', 'most', 'practitioners', 'use', 'a', 'procedure', 'called', 'stochastic', 'gradient', 'descent', '(SGD)']), (0.005003253854515983, ['For', 'classification', 'tasks,', 'higher', 'layers', 'of', 'representation', 'amplify', 'aspects', 'of', 'the', 'input', 'that', 'are', 'important', 'for', 'discrimination', 'and', 'suppress', 'irrelevant', 'variations']), (0.004954535041910463, ['By', '2012,', 'versions', 'of', 'the', 'deep', 'net', 'from', '200', 'were', 'being', 'developed', 'by', 'many', 'of', 'the', 'major', 'speech', 'groups', 'and', 'were', 'already', 'being', 'deployed', 'in', 'Android', 'phones']), (0.0049433517795891245, ['It', 'is', 'called', 'stochastic', 'because', 'each', 'small', 'set', 'of', 'examples', 'gives', 'a', 'noisy', 'estimate', 'of', 'the', 'average', 'gradient', 'over', 'all', 'examples']), (0.004938065484183139, ['At', 'the', 'pixel', 'level,', 'images', 'of', 'two', 'Samoyeds', 'in', 'different', 'poses', 'and', 'in', 'different', 'environments', 'may', 'be', 'very', 'different', 'from', 'each', 'other,', 'whereas', 'two', 'images', 'of', 'a', 'Samoyed', 'and', 'a', 'wolf', 'in', 'the', 'same', 'position', 'and', 'on', 'similar', 'backgrounds', 'may', 'be', 'very', 'similar', 'to', 'eachother']), (0.0049315913515562805, ['Then', 'a', 'non-linear', 'function', 'f(.)', 'is', 'applied', 'to', 'z', 'to', 'get', 'the', 'output', 'of', 'the', 'unit']), (0.004900480530748913, ['We', 'expect', 'systems', 'that', 'use', 'RNNs', 'to', 'understand', 'sentences', 'or', 'whole', 'documents', 'will', 'become', 'much', 'better', 'when', 'they', 'learn', 'strategies', 'for', 'selectively', 'attending', 'to', 'one', 'part', 'at', 'a', 'time']), (0.004876065040047705, ['Memory', 'networks', 'can', 'be', 'trained', 'to', 'keep', 'track', 'of', 'the', 'state', 'of', 'the', 'world', 'in', 'a', 'setting', 'similar', 'to', 'a', 'text', 'adventure', 'game', 'and', 'after', 'reading', 'a', 'story,', 'they', 'can', 'answer', 'questions', 'that', 'require', 'complex', 'inference']), (0.004818669196454397, ['These', 'were', 'all', 'tasks', 'in', 'which', 'labelled', 'data', 'was', 'relatively', 'abundant,', 'such', 'as', 'traffic', 'sign', 'recognition,', 'the', 'segmentation', 'of', 'biological', 'images', 'particularly', 'for', 'connectomics,', 'and', 'the', 'detection', 'of', 'faces,text,', 'pedestrians', 'and', 'human', 'bodies', 'in', 'natural', 'images']), (0.004816642177699245, ['A', 'recent', 'stunning', 'demonstration', 'combines', 'ConvNets', 'and', 'recurrent', 'net', 'modules', 'for', 'the', 'generation', 'of', 'image', 'captions.Recent', 'ConvNet', 'architectures', 'have', '10', 'to', '20', 'layers', 'of', 'ReLUs,', 'hundreds', 'of', 'millions', 'of', 'weights,', 'and', 'billions', 'of', 'connections', 'between', 'units']), (0.004790413141851209, ['All', 'units', 'in', 'a', 'feature', 'map', 'share', 'the', 'same', 'filter', 'bank']), (0.0047857415302557625, ['The', 'document', 'reading', 'system', 'used', 'a', 'ConvNet', 'trained', 'jointly', 'with', 'a', 'probabilistic', 'model', 'that', 'implemented', 'language', 'constraints']), (0.004783599630775438, ['Many', 'data', 'modalities', 'are', 'in', 'the', 'form', 'of', 'multiple', 'arrays:', '1D', 'for', 'signals', 'and', 'sequences,', 'including', 'language;', '2D', 'for', 'images', 'or', 'audio', 'spectrograms;and', '3D', 'for', 'video', 'or', 'volumetric', 'images']), (0.004753946273934542, ['The', 'memory', 'is', 'used', 'to', 'remember', 'the', 'story', 'about', 'which', 'the', 'network', 'is', 'later', 'asked', 'to', 'answer', 'questions']), (0.004722206451977547, ['Each', 'word', 'in', 'the', 'context', 'is', 'presented', 'to', 'the', 'network', 'as', 'a', 'one-of-N', 'vector,', 'that', 'is,', 'one', 'component', 'has', 'a', 'value', 'of', '1', 'and', 'the', 'rest', 'are', '0']), (0.004700866063863403, ['It', 'achieved', 'record-breaking', 'results', 'on', 'a', 'standard', 'speech', 'recognition', 'benchmark', 'that', 'used', 'a', 'small', 'vocabulary', 'and', 'was', 'quickly', 'developed', 'to', 'give', 'record-breaking', 'results', 'on', 'a', 'large', 'vocabulary', 'task']), (0.004611726984828909, ['First,', 'in', 'array', 'data', 'such', 'as', 'images,', 'local', 'groups', 'of', 'values', 'are', 'often', 'highly', 'correlated,', 'forming', 'distinctive', 'local', 'motifs', 'that', 'are', 'easily', 'detected']), (0.004579716816264087, ['First,learning', 'distributed', 'representations', 'enable', 'generalization', 'to', 'new', 'combinations', 'of', 'the', 'values', 'of', 'learned', 'features', 'beyond', 'those', 'seen', 'during', 'training', '(for', 'example,', '2n', 'combinations', 'are', 'possible', 'with', 'n', 'binary', 'features)']), (0.004571804021081199, ['It', 'was', 'widely', 'thought', 'that', 'learning', 'useful,', 'multistage,', 'feature', 'extractors', 'with', 'little', 'prior', 'knowledge', 'was', 'infeasible']), (0.004546775487722373, ['This', 'consists', 'of', 'showing', 'the', 'input', 'vector', 'for', 'a', 'few', 'examples,', 'computing', 'the', 'outputs', 'and', 'the', 'errors,', 'computing', 'the', 'average', 'gradient', 'for', 'those', 'examples,', 'and', 'adjusting', 'the', 'weights', 'accordingly']), (0.0045184654675459335, ['These', 'semantic', 'features', 'were', 'not', 'explicitly', 'present', 'in', 'the', 'input']), (0.004502366513754133, ['The', 'third', 'layer', 'may', 'assemble', 'motifs', 'into', 'larger', 'combinations', 'that', 'correspond', 'to', 'parts', 'of', 'familiar', 'objects,', 'and', 'subsequent', 'layers', 'would', 'detect', 'objects', 'as', 'combinations', 'of', 'these', 'parts']), (0.004456922757721756, ['The', 'second', 'layer', 'typically', 'detects', 'motifs', 'by', 'spotting', 'particular', 'arrangements', 'of', 'edges,', 'regardless', 'of', 'small', 'variations', 'in', 'the', 'edge', 'positions']), (0.004324697062311239, ['Deep-learning', 'methods', 'are', 'representation-learning', 'methods', 'with', 'multiple', 'levels', 'of', 'representation,', 'obtained', 'by', 'composing', 'simple', 'but', 'non-linear', 'modules', 'that', 'each', 'transform', 'the', 'representation', 'at', 'one', 'level', '(starting', 'with', 'the', 'raw', 'input)', 'into', 'a', 'representation', 'at', 'a', 'higher,', 'slightly', 'more', 'abstract', 'level']), (0.004285946613524023, ['These', 'adjustable', 'parameters,', 'often', 'called', 'weights,', 'are', 'real', 'numbers', 'that', 'can', 'be', 'seen', 'as', '‘knobs’', 'that', 'define', 'the', 'input–output', 'function', 'of', 'the', 'machine']), (0.004283410367416226, ['Among', 'other', 'things,', 'they', 'can', 'learn', 'to', 'output', 'a', 'sorted', 'list', 'of', 'symbols', 'when', 'their', 'input', 'consists', 'of', 'an', 'unsorted', 'sequence', 'in', 'which', 'each', 'symbol', 'is', 'accompanied', 'by', 'a', 'real', 'value', 'that', 'indicates', 'its', 'priority', 'in', 'the', 'list']), (0.004249726782031758, ['For', 'tasks', 'that', 'involve', 'sequential', 'inputs,', 'such', 'as', 'speech', 'and', 'language,', 'it', 'is', 'often', 'better', 'to', 'use', 'RNNs']), (0.0041998349833237865, ['From', 'the', 'earliest', 'days', 'of', 'pattern', 'recognition,', 'the', 'aim', 'of', 'researchers', 'has', 'been', 'to', 'replace', 'hand-engineered', 'features', 'with', 'trainable', 'multi', 'layer', 'networks,', 'but', 'despite', 'its', 'simplicity,', 'the', 'solution', 'was', 'not', 'widely', 'understood', 'until', 'the', 'mid', '1980s']), (0.0041193914886864524, ['Each', 'module', 'in', 'the', 'stack', 'transforms', 'its', 'input', 'to', 'increase', 'both', 'the', 'selectivity', 'and', 'the', 'invariance', 'of', 'the', 'representation']), (0.004108214206308223, ['This', 'success', 'came', 'from', 'the', 'efficient', 'use', 'of', 'GPUs,ReLUs,', 'a', 'new', 'regularization', 'technique', 'called', 'dropout,', 'and', 'techniques', 'to', 'generate', 'more', 'training', 'examples', 'by', 'deforming', 'the', 'existing', 'ones']), (0.004061881629790203, ['Machine-learning', 'systems', 'are', 'used', 'to', 'identify', 'objects', 'in', 'images,', 'transcribe', 'speech', 'into', 'text,', 'match', 'news', 'items,', 'posts', 'or', 'products', 'with', 'users’', 'interests,', 'and', 'select', 'relevant', 'results', 'of', 'search']), (0.0040290812394928825, ['Other', 'applications', 'gaining', 'importance', 'involve', 'natural', 'language', 'understanding', 'and', 'speech', 'recognition.Despite', 'these', 'successes,', 'ConvNets', 'were', 'largely', 'forsaken', 'by', 'the', 'mainstream', 'computer-vision', 'and', 'machine-learning', 'communities', 'until', 'the', 'ImageNet', 'competition', 'in', '2012']), (0.004007739741500992, ['Two', 'or', 'three', 'stages', 'of', 'convolution,', 'non-linearity', 'and', 'pooling', 'are', 'stacked,', 'followed', 'by', 'more', 'convolutional', 'and', 'fully-connected', 'layers']), (0.003996828002819787, ['Hence,', 'it', 'does', 'not', 'much', 'matter', 'which', 'of', 'these', 'saddle', 'points', 'the', 'algorithm', 'gets', 'stuck', 'at.Interest', 'in', 'deep', 'feedforward', 'networks', 'was', 'revived', 'around', '2006', 'by', 'a', 'group', 'of', 'researchers', 'brought', 'together', 'by', 'the', 'Canadian', 'Institute', 'for', 'Advanced', 'Research', '(CIFAR)']), (0.003970553339970584, ['For', 'smaller', 'data', 'sets,unsupervised', 'pre-training', 'helps', 'to', 'prevent', 'overfitting,', 'leading', 'to', 'significantly', 'better', 'generalization', 'when', 'the', 'number', 'of', 'labelled', 'examples', 'is', 'small,', 'or', 'in', 'a', 'transfer', 'setting', 'where', 'we', 'have', 'lots', 'of', 'examples', 'for', 'some', '‘source’', 'tasks', 'but', 'very', 'few', 'for', 'some', '‘target’', 'tasks']), (0.0038917975119274494, ['It', 'has', 'turned', 'out', 'to', 'be', 'very', 'good', 'at', 'discovering', 'intricate', 'structures', 'in', 'high-dimensional', 'data', 'and', 'is', 'therefore', 'applicable', 'to', 'many', 'domains', 'of', 'science,', 'business', 'and', 'government']), (0.0038683456772400115, ['Human', 'and', 'animal', 'learning', 'is', 'largely', 'unsupervised:we', 'discover', 'the', 'structure', 'of', 'the', 'world', 'by', 'observing', 'it,', 'not', 'by', 'being', 'told', 'the', 'name', 'of', 'every', 'object.Human', 'vision', 'is', 'an', 'active', 'process', 'that', 'sequentially', 'samples', 'the', 'optic', 'array', 'in', 'an', 'intelligent,', 'task-specific', 'way', 'using', 'a', 'small,', 'high-resolution', 'fovea', 'with', 'a', 'large,', 'low-resolution', 'surround']), (0.003851147278764769, ['But', 'problems', 'such', 'as', 'image', 'and', 'speech', 'recognition', 'require', 'the', 'input–output', 'function', 'to', 'be', 'insensitive', 'to', 'irrelevant', 'variations', 'of', 'the', 'input,', 'such', 'as', 'variations', 'in', 'position,', 'orientation', 'or', 'illumination', 'of', 'an', 'object,', 'or', 'variations', 'in', 'the', 'pitch', 'or', 'accent', 'of', 'speech,', 'while', 'being', 'very', 'sensitive', 'to', 'particular', 'minute', 'variations', '(for', 'example,the', 'difference', 'between', 'a', 'white', 'wolf', 'and', 'a', 'breed', 'of', 'wolf-like', 'white', 'dog', 'called', 'a', 'Samoyed)']), (0.0038411357710651847, ['A', 'major', 'recent', 'practical', 'success', 'of', 'ConvNets', 'is', 'face', 'recognition.Importantly,', 'images', 'can', 'be', 'labelled', 'at', 'the', 'pixel', 'level,', 'which', 'will', 'have', 'applications', 'in', 'technology,', 'including', 'autonomous', 'mobile', 'robots', 'and', 'self-driving', 'cars']), (0.0038286538242168697, ['The', 'weight', 'vector', 'is', 'then', 'adjusted', 'in', 'the', 'opposite', 'direction', 'to', 'the', 'gradient', 'vector']), (0.0037748894368920894, ['A', 'special', 'unit', 'called', 'the', 'memory', 'cell', 'acts', 'like', 'an', 'accumulator', 'or', 'a', 'gated', 'leaky', 'neuron:', 'it', 'has', 'a', 'connection', 'to', 'itself', 'at', 'the', 'next', 'time', 'step', 'that', 'has', 'a', 'weight', 'of', 'one,', 'so', 'it', 'copies', 'its', 'own', 'real-valued', 'state', 'and', 'accumulates', 'the', 'external', 'signal,', 'but', 'this', 'self-connection', 'is', 'multiplicatively', 'gated', 'by', 'another', 'unit', 'that', 'learns', 'to', 'decide', 'when', 'to', 'clear', 'the', 'content', 'of', 'the', 'memory']), (0.0037735223802105077, ['We', 'want', 'the', 'desired', 'category', 'to', 'have', 'the', 'highest', 'score', 'of', 'all', 'categories,', 'but', 'this', 'is', 'unlikely', 'to', 'happen', 'before', 'training.We', 'compute', 'an', 'objective', 'function', 'that', 'measures', 'the', 'error', '(or', 'distance)', 'between', 'the', 'output', 'scores', 'and', 'the', 'desired', 'pattern', 'of', 'scores']), (0.0037480090119468936, ['This', 'simple', 'procedure', 'usually', 'finds', 'a', 'good', 'set', 'of', 'weights', 'surprisingly', 'quickly', 'when', 'compared', 'with', 'far', 'more', 'elaborate', 'optimization', 'techniques']), (0.003736296197036163, ['Once', 'the', '∂E/∂z', 'k', 'is', 'known,', 'the', 'error-derivative', 'for', 'the', 'weight', 'wjk', 'on', 'the', 'connection', 'from', 'unit', 'j', 'in', 'the', 'layer', 'below', 'is', 'just', 'yj', '∂E/∂zk']), (0.0037025248389434694, ['It', 'is', 'more', 'compatible', 'with', 'the', 'view', 'that', 'everyday', 'reasoning', 'involves', 'many', 'simultaneous', 'analogies', 'that', 'each', 'contribute', 'plausibility', 'to', 'a', 'conclusion.Instead', 'of', 'translating', 'the', 'meaning', 'of', 'a', 'French', 'sentence', 'into', 'an', 'English', 'sentence,', 'one', 'can', 'learn', 'to', '‘translate’', 'the', 'meaning', 'of', 'an', 'image', 'into', 'an', 'English', 'sentence']), (0.003688950396357352, ['Although', 'we', 'have', 'not', 'focused', 'on', 'it', 'in', 'this', 'Review,', 'we', 'expect', 'unsupervised', 'learning', 'to', 'become', 'far', 'more', 'important', 'in', 'the', 'longer', 'term']), (0.0036873996214427346, ['Memory', 'networks', 'have', 'yielded', 'excellent', 'performance', 'on', 'standard', 'question-answering', 'benchmarks']), (0.003686587472790131, ['The', 'analysis', 'seems', 'to', 'show', 'that', 'saddle', 'points', 'with', 'only', 'a', 'few', 'downward', 'curving', 'directions', 'are', 'present', 'in', 'very', 'large', 'numbers,', 'but', 'almost', 'all', 'of', 'them', 'have', 'very', 'similar', 'values', 'of', 'the', 'objective', 'function']), (0.0036600014047103334, ['The', 'chain', 'rule', 'of', 'derivatives', 'tells', 'us', 'how', 'two', 'small', 'effects', '(that', 'of', 'a', 'small', 'change', 'of', 'x', 'on', 'y,', 'and', 'that', 'of', 'y', 'on', 'z)', 'are', 'composed']), (0.00364147753949516, ['With', 'multiple', 'non-linear', 'layers,', 'say', 'a', 'depth', 'of', '5', 'to', '20,', 'a', 'system', 'can', 'implement', 'extremely', 'intricate', 'functions', 'of', 'its', 'inputs', 'that', 'are', 'simultaneously', 'sensitive', 'to', 'minute', 'details—', 'distinguishing', 'Samoyeds', 'from', 'white', 'wolves', '—', 'and', 'insensitive', 'to', 'large', 'irrelevant', 'variations', 'such', 'as', 'the', 'background,', 'pose,', 'lighting', 'and', 'surrounding', 'objects']), (0.0036224572809763806, ['The', 'objective', 'function,', 'averaged', 'over', 'all', 'the', 'training', 'examples,', 'can', 'be', 'seen', 'as', 'a', 'kind', 'of', 'hilly', 'landscape', 'in', 'the', 'high-dimensional', 'space', 'of', 'weight', 'values']), (0.003618855612031847, ['This', 'rather', 'naive', 'way', 'of', 'performing', 'machine', 'translation', 'has', 'quickly', 'become', 'competitive', 'with', 'the', 'state-of-the-art,and', 'this', 'raises', 'serious', 'doubts', 'about', 'whether', 'understanding', 'a', 'sentence', 'requires', 'anything', 'like', 'the', 'internal', 'symbolic', 'expressions', 'that', 'are', 'manipulated', 'by', 'using', 'inference', 'rules']), (0.0036069967603743133, ['This', 'serves', 'to', 'test', 'the', 'generalization', 'ability', 'of', 'the', 'machine', '—', 'its', 'ability', 'to', 'produce', 'sensible', 'answers', 'on', 'new', 'inputs', 'that', 'it', 'has', 'never', 'seen', 'during', 'training']), (0.003592088495214381, ['In', 'images,', 'local', 'combinations', 'of', 'edges', 'form', 'motifs,', 'motifs', 'assemble', 'into', 'parts,', 'and', 'parts', 'form', 'objects']), (0.003487474881666275, ['These', 'methods', 'have', 'dramatically', 'improved', 'the', 'state-of-the-art', 'in', 'speech', 'recognition,', 'visual', 'object', 'recognition,', 'object', 'detection', 'and', 'many', 'other', 'domains', 'such', 'as', 'drug', 'discovery', 'and', 'genomics']), (0.003452383209897321, ['Since', 'the', '1960s', 'we', 'have', 'known', 'that', 'linear', 'classifiers', 'can', 'only', 'carve', 'their', 'input', 'space', 'into', 'very', 'simple', 'regions,', 'namely', 'half-spaces', 'separated', 'by', 'a', 'hyperplane']), (0.0034191272601114928, ['In2009,', 'the', 'approach', 'was', 'used', 'to', 'map', 'short', 'temporal', 'windows', 'of', 'coefficients', 'extracted', 'from', 'a', 'sound', 'wave', 'to', 'a', 'set', 'of', 'probabilities', 'for', 'thevarious', 'fragments', 'of', 'speech', 'that', 'might', 'be', 'represented', 'by', 'the', 'framein', 'the', 'centre', 'of', 'the', 'window']), (0.003356092666792195, ['A', 'small', 'change', 'Δx', 'in', 'x', 'gets', 'transformed', 'first', 'into', 'a', 'small', 'change', 'Δy', 'in', 'y', 'by', 'getting', 'multiplied', 'by', '∂y/∂x', '(that', 'is,', 'the', 'definition', 'of', 'partial', 'derivative)']), (0.003350468822120796, ['Substituting', 'one', 'equation', 'into', 'the', 'other', 'gives', 'the', 'chain', 'rule', 'of', 'derivatives', '—', 'how', 'Δx', 'gets', 'turned', 'into', 'Δz', 'through', 'multiplication', 'by', 'the', 'product', 'of', '∂y/∂x', 'and', '∂z/∂x']), (0.0033251922319770663, ['This', 'success', 'has', 'brought', 'about', 'a', 'revolution', 'in', 'computer', 'vision;ConvNets', 'are', 'now', 'the', 'dominant', 'approach', 'for', 'almost', 'all', 'recognition', 'and', 'detection', 'tasks', 'and', 'approach', 'human', 'performance', 'on', 'some', 'tasks']), (0.003214368995042875, ['Second,', 'the', 'local', 'statistics', 'of', 'images', 'and', 'other', 'signals', 'are', 'invariant', 'to', 'location']), (0.003203031706531347, ['The', 'machine', 'then', 'modifies', 'its', 'internal', 'adjustable', 'parameters', 'to', 'reduce', 'this', 'error']), (0.0031660699781430753, ['Neural', 'Turing', 'machines', 'can', 'be', 'taught', '‘algorithms’']), (0.003057395641283022, ['The', 'conventional', 'option', 'is', 'to', 'hand', 'design', 'good', 'feature', 'extractors,', 'which', 'requires', 'a', 'considerable', 'amount', 'of', 'engineering', 'skill', 'and', 'domain', 'expertise']), (0.0030510165645172326, ['The', 'result', 'of', 'this', 'local', 'weighted', 'sum', 'is', 'then', 'passed', 'through', 'a', 'non-linearity', 'such', 'as', 'a', 'ReLU']), (0.003021021537537963, ['A', 'number', 'of', 'ConvNet-based', 'optical', 'character', 'recognition', 'and', 'handwriting', 'recognition', 'systems', 'were', 'later', 'deployed', 'by', 'Microsoft']), (0.003011222391671593, ['d,', 'The', 'equations', 'used', 'for', 'computing', 'the', 'backward', 'pass']), (0.002956414405546762, ['Companies', 'such', 'as', 'Mobileye', 'and', 'NVIDIA', 'are', 'using', 'such', 'ConvNet-based', 'methods', 'in', 'their', 'upcoming', 'vision', 'systems', 'for', 'cars']), (0.0029548792104905188, ['Because', 'the', 'relative', 'positions', 'of', 'the', 'features', 'forming', 'a', 'motif', 'can', 'vary', 'somewhat,reliably', 'detecting', 'the', 'motif', 'can', 'be', 'done', 'by', 'coarse-graining', 'the', 'position', 'of', 'each', 'feature']), (0.0029194830379389407, ['Similar', 'hierarchies', 'exist', 'in', 'speech', 'and', 'text', 'from', 'sounds', 'to', 'phones,', 'phonemes,', 'syllables,', 'words', 'and', 'sentences']), (0.002909035040894146, ['In', 'addition', 'to', 'beating', 'records', 'in', 'image', 'recognition', 'and', 'speech', 'recognition,', 'it', 'has', 'beaten', 'other', 'machine-learning', 'techniques', 'at', 'predicting', 'the', 'activity', 'of', 'potential', 'drug', 'molecules,', 'analysing', 'particle', 'accelerator', 'data,reconstructing', 'brain', 'circuits,', 'and', 'predicting', 'the', 'effects', 'of', 'mutations', 'in', 'non-coding', 'DNA', 'on', 'gene', 'expression', 'and', 'disease']), (0.002859962838585146, ['Overall,', 'this', 'process', 'generates', 'sequences', 'of', 'French', 'words', 'according', 'to', 'a', 'probability', 'distribution', 'that', 'depends', 'on', 'the', 'English', 'sentence']), (0.0027888536721440847, ['When', 'ConvNet', 'models', 'and', 'monkeys', 'are', 'shown', 'the', 'same', 'picture,', 'the', 'activations', 'of', 'high-level', 'units', 'in', 'the', 'ConvNet', 'explains', 'half', 'of', 'the', 'variance', 'of', 'random', 'sets', 'of', '160', 'neurons', 'in', 'the', 'monkey’s', 'infero', 'temporal', 'cortex']), (0.002669265719450759, ['raw', 'pixels', 'could', 'not', 'possibly', 'distinguish', 'the', 'latter', 'two,', 'while', 'putting', 'the', 'former', 'two', 'in', 'the', 'same', 'category']), (0.0026429921355315728, ['This', 'gives', 'yl−tl', 'if', 'the', 'cost', 'function', 'for', 'unit', 'l', 'is', '0.5(yl−tl),', 'where', 'tl', 'is', 'the', 'target', 'value']), (0.0025502215048919773, ['Recent', 'theoretical', 'and', 'empirical', 'results', 'strongly', 'suggest', 'that', 'local', 'minima', 'are', 'not', 'a', 'serious', 'issue', 'in', 'general']), (0.0024627313132562388, ['Instead,', 'the', 'landscape', 'is', 'packed', 'with', 'a', 'combinatorially', 'large', 'number', 'of', 'saddle', 'points', 'where', 'the', 'gradient', 'is', 'zero,', 'and', 'the', 'surface', 'curves', 'up', 'in', 'most', 'dimensions', 'and', 'curves', 'down', 'in', 'the', 'remainder']), (0.0024327283541324034, ['It', 'also', 'works', 'when', 'x,', 'y', 'and', 'z', 'are', 'vectors', '(and', 'the', 'derivatives', 'are', 'Jacobian', 'matrices)']), (0.0024272911419914328, ['With', 'the', 'composition', 'of', 'enough', 'such', 'transformations,', 'very', 'complex', 'functions', 'can', 'be', 'learned']), (0.00240834305312259, ['Imagine', 'that', 'we', 'want', 'to', 'build', 'a', 'system', 'that', 'can', 'classify', 'images', 'as', 'containing,', 'say,', 'a', 'house,', 'a', 'car,', 'a', 'person', 'or', 'a', 'pet']), (0.002283713828697044, ['Regardless', 'of', 'the', 'initial', 'conditions,', 'the', 'system', 'nearly', 'always', 'reaches', 'solutions', 'of', 'very', 'similar', 'quality']), (0.0021733074331110446, ['It', 'has', 'no', 'internal', 'structure', 'that', 'is', 'relevant', 'to', 'its', 'use;', 'and', 'to', 'reason', 'with', 'symbols,', 'they', 'must', 'be', 'bound', 'to', 'the', 'variables', 'in', 'judiciously', 'chosen', 'rules', 'of', 'inference']), (0.002081665350252903, ['By', 'the', 'late', '1990s', 'this', 'system', 'was', 'reading', 'over', '10%', 'of', 'all', 'the', 'cheques', 'in', 'the', 'United', 'States']), (0.001984098890399546, ['Similarly,', 'the', 'changeΔy', 'creates', 'a', 'change', 'Δz', 'in', 'z']), (0.001724880707982421, ['ConvNets', 'are', 'easily', 'amenable', 'to', 'efficient', 'hardware', 'implementations', 'in', 'chips', 'or', 'field-programmable', 'gate', 'arrays']), (0.0016064764657643216, ['The', 'reason', 'for', 'this', 'architecture', 'is', 'twofold']), (0.0015847315313196994, ['Both', 'of', 'these', 'advantages', 'arise', 'from', 'the', 'power', 'of', 'composition', 'and', 'depend', 'on', 'the', 'underlying', 'data-generating', 'distribution', 'having', 'an', 'appropriate', 'componential', 'structure']), (0.0013152518744283896, ['In', 'the', 'logic-inspired', 'paradigm,', 'an', 'instance', 'of', 'a', 'symbol', 'is', 'something', 'for', 'which', 'the', 'only', 'property', 'is', 'that', 'it', 'is', 'either', 'identical', 'or', 'non-identical', 'to', 'other', 'symbol', 'instances'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2trQoFnzpJX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}